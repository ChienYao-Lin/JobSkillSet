{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a942fe32",
   "metadata": {},
   "source": [
    "# Data Preparation - Get Data and Label it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff12d3a",
   "metadata": {},
   "source": [
    "## Import Package for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6471899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, os, spacy, unicodedata, json\n",
    "from spacy import displacy\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165bba2",
   "metadata": {},
   "source": [
    "## Scrap data\n",
    "I scrape [SEEK](https://www.seek.com.au) to extract the information of recruitment advertisement for data analyst, data scientist and data engineer. There are two steps in this part.\n",
    "1. Get Job Urls: parse the search pages to get the url of each job advertisement.\n",
    "2. Get Job Description: extract the text content for all jobs from the urls I scraped before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6bce83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:24<00:00,  2.43s/it]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:24<00:00,  2.43s/it]\n",
      "100%|███████████████████████████████████████████| 10/10 [00:23<00:00,  2.38s/it]\n",
      "100%|█████████████████████████████████████████| 506/506 [07:01<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "def getUrlsSeek(keyWord, page):\n",
    "    keyString = keyWord.replace(' ', '-')\n",
    "    mainUrl = 'https://www.seek.com.au'\n",
    "    jobUrlList = []\n",
    "    for i in tqdm(range(1, 1+page)):\n",
    "        time.sleep(1)\n",
    "        url = f\"{mainUrl}/{keyString}-jobs?page={i}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        jobs = soup.find_all(\"article\")\n",
    "        for job in jobs:\n",
    "            jobid = job[\"data-job-id\"]\n",
    "            jobUrlList.append(f\"https://www.seek.com.au/job/{jobid}\")\n",
    "        time.sleep(1)\n",
    "    return jobUrlList\n",
    "\n",
    "def getContent(urlList):\n",
    "    tags = [\"li\", \"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]\n",
    "    text = []\n",
    "    for url in tqdm(urlList):\n",
    "        time.sleep(0.5)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        details = soup.find(\"div\", {\"data-automation\": \"jobAdDetails\"})\n",
    "        for tag in tags:\n",
    "            desc_all_tag = details.find_all(tag)\n",
    "            text = [*text, *[desc_tag.text for desc_tag in desc_all_tag]]\n",
    "    return list(set(text))\n",
    "\n",
    "\n",
    "job_title = [\"data analyst\", \"data scientist\", \"data engineer\"]\n",
    "urlList = []\n",
    "for job in job_title:\n",
    "    urlList = [*urlList, *getUrlsSeek(job, page = 10)]\n",
    "urlList = list(set(urlList))\n",
    "text = getContent(urlList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26629b6",
   "metadata": {},
   "source": [
    "## Split text by sentence then write it into text file\n",
    "Here I used spacy 'en_core_web_sm' model to split the description of jobs into sentences and write these sentences decoded by unicodedata into text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9203ecb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9445/9445 [00:47<00:00, 198.80it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentences = []\n",
    "for t in tqdm(text):\n",
    "    sentences = [*sentences, *[i for i in nlp(t).sents]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea928a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[If you have a passion for learning new technologies, want to deliver real client impact and work with like-minded technologists, Hypetap is the place to grow your career and have fun in the process!,\n",
       " We are considering applications Australia wide.,\n",
       " Advanced programming skills in SQL & Python,\n",
       " To be eligible for this position please refer to the following criteria:,\n",
       " Salary range $4566.20 to $4900.40 p.f.,\n",
       " Accelerated career growth opportunities.]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1948e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../data/data_ad.txt\"):\n",
    "    os.remove(\"../data/data_ad.txt\")\n",
    "with open(\"../data/data_ad.txt\", \"w\") as f:\n",
    "    for sen in sentences:\n",
    "        f.write(unicodedata.normalize(\"NFKD\", str(sen))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc89d65",
   "metadata": {},
   "source": [
    "## Create patterns for EntityRuler\n",
    "The skill entity list was created by scraping [AngelList](https://angel.co/)'s skill report, but the page is not available now. Here is how the page looked like. ![](https://i.imgur.com/K9QCrAU.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08af57a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTML</td>\n",
       "      <td>SKILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Java</td>\n",
       "      <td>SKILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Javascript</td>\n",
       "      <td>SKILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>SKILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSS</td>\n",
       "      <td>SKILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text   Type\n",
       "0        HTML  SKILL\n",
       "1        Java  SKILL\n",
       "2  Javascript  SKILL\n",
       "3      Python  SKILL\n",
       "4         CSS  SKILL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/entitylist.csv')\n",
    "df = df.dropna()\n",
    "ad_skills_regular = [{\"label\": row[1], \"pattern\": row[0]} for row in zip(df['Text'], df['Type'])]\n",
    "ad_skills_lower = [{\"label\": row[1], \"pattern\": row[0].lower()} for row in zip(df['Text'], df['Type'])]\n",
    "ad_skills = [*ad_skills_regular, *ad_skills_lower]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0dfba",
   "metadata": {},
   "source": [
    "### The format of one pattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75290f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'SKILL', 'pattern': 'HTML'},\n",
       " {'label': 'SKILL', 'pattern': 'Java'},\n",
       " {'label': 'SKILL', 'pattern': 'Javascript'},\n",
       " {'label': 'SKILL', 'pattern': 'Python'},\n",
       " {'label': 'SKILL', 'pattern': 'CSS'},\n",
       " {'label': 'SKILL', 'pattern': 'C++'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_skills[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b625ca2",
   "metadata": {},
   "source": [
    "## Build simple NLP model with EntityRuler and then annotate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3a6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "def generate_rule_based_nlp(patterns):\n",
    "    nlp = English()\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    return nlp\n",
    "\n",
    "def test_model(model, text):\n",
    "    doc = model(text)\n",
    "    entities = []\n",
    "    results = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "    if len(entities) > 0:\n",
    "        results = [text, {\"entities\" : entities}]\n",
    "    return results\n",
    "\n",
    "\n",
    "nlp = generate_rule_based_nlp(ad_skills)\n",
    "ad_data = []\n",
    "\n",
    "with open(\"../data/data_ad.txt\", \"r\") as f:\n",
    "    data = f.read().splitlines()\n",
    "    for line in data:\n",
    "        result = test_model(nlp, line)\n",
    "        if result:\n",
    "            ad_data = [*ad_data, result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce14a1",
   "metadata": {},
   "source": [
    "## Test annotation and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83110f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Machine Learning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Engineering\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " skills who use advanced techniques such as \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Deep Learning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " (GPU accelerated), \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       ", Graph \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ML\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " as well as other predictive modelling methods to identify \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    business opportunities\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
       "</mark>\n",
       " from a variety of data sources</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_text = \"Machine Learning Engineering skills who use advanced techniques such as Deep Learning (GPU accelerated), NLP, Graph ML as well as other predictive modelling methods to identify business opportunities from a variety of data sources\"\n",
    "doc = nlp(test_text)\n",
    "displacy.render(doc, style=\"ent\")\n",
    "nlp.to_disk('../model/entRuler')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302eadd",
   "metadata": {},
   "source": [
    "## Write processed data into json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2e65bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../data/ad_data_labeled.json\"):\n",
    "    os.remove(\"../data/ad_data_labeled.json\")\n",
    "with open(\"../data/ad_data_labeled.json\", \"w\", encoding = \"utf-8\") as f:\n",
    "    json.dump(ad_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcda0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
